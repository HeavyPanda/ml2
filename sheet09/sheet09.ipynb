{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Hidden Markov Models (60 P)\n",
    "\n",
    "In this exercise, you will experiment with hidden Markov models, in particular, applying them to modeling character sequences, and analyzing the learned solution. As a starting point, you are provided in the file `hmm.py` with a basic implementation of an HMM and of the Baum-Welch training algorithm. The names of variables used in the code and the references to equations are taken from the HMM paper by Rabiner et al. downloable from ISIS. In addition to the variables described in this paper, we use two additional variables: $Z$ for the emission probabilities of observations $O$, and $\\psi$ (i.e. psi) for collecting the statistics of Equation (40c).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question 1: Analysis of a small HMM (30 P)\n",
    "\n",
    "We first look at a toy example of an HMM trained on a binary sequence. The training procedure below consists of 100 iterations of the Baum-Welch procedure. It runs the HMM learning algorithm for some toy binary data and prints the parameters learned by the HMM (i.e. matrices $A$ and $B$).\n",
    "\n",
    "###Question 1a: Qualitative Analysis (15 P)\n",
    "\n",
    "* *Run* the code several times to check that the behavior is consistent.\n",
    "* *Describe* qualitatively the solution $A,B$ learned by the model.\n",
    "* *Explain* how the solution $\\lambda = (A,B)$ relates to the sequence of observations $O$ that has been modeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration nr: 0\n",
      "A\n",
      "0.000 0.000 0.000 1.000\n",
      "0.000 0.000 1.000 0.000\n",
      "1.000 0.000 0.000 0.000\n",
      "0.000 1.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.800 0.200\n",
      "0.000 1.000\n",
      "0.720 0.280\n",
      "0.880 0.120\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 1\n",
      "A\n",
      "0.000 1.000 0.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "1.000 0.000 0.000 0.000\n",
      "0.000 0.000 1.000 0.000\n",
      " \n",
      "B\n",
      "0.880 0.120\n",
      "0.000 1.000\n",
      "0.800 0.200\n",
      "0.720 0.280\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 2\n",
      "A\n",
      "0.000 0.000 1.000 0.000\n",
      "1.000 0.000 0.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "0.000 1.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.880 0.120\n",
      "0.800 0.200\n",
      "0.000 1.000\n",
      "0.720 0.280\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 3\n",
      "A\n",
      "0.000 0.000 1.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "0.000 1.000 0.000 0.000\n",
      "1.000 0.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.000 1.000\n",
      "0.800 0.200\n",
      "0.720 0.280\n",
      "0.880 0.120\n",
      " \n",
      "Pi\n",
      "1.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 4\n",
      "A\n",
      "0.000 0.000 0.000 1.000\n",
      "0.000 0.000 1.000 0.000\n",
      "1.000 0.000 0.000 0.000\n",
      "0.000 1.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.880 0.120\n",
      "0.720 0.280\n",
      "0.800 0.200\n",
      "0.000 1.000\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "1.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 5\n",
      "A\n",
      "0.000 0.000 1.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "0.000 1.000 0.000 0.000\n",
      "1.000 0.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.880 0.120\n",
      "0.720 0.280\n",
      "0.000 1.000\n",
      "0.800 0.200\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 6\n",
      "A\n",
      "0.000 1.000 0.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "1.000 0.000 0.000 0.000\n",
      "0.000 0.000 1.000 0.000\n",
      " \n",
      "B\n",
      "0.880 0.120\n",
      "0.000 1.000\n",
      "0.800 0.200\n",
      "0.720 0.280\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 7\n",
      "A\n",
      "0.000 1.000 0.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "1.000 0.000 0.000 0.000\n",
      "0.000 0.000 1.000 0.000\n",
      " \n",
      "B\n",
      "0.800 0.200\n",
      "0.880 0.120\n",
      "0.720 0.280\n",
      "0.000 1.000\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "1.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 8\n",
      "A\n",
      "0.000 0.000 0.038 0.962\n",
      "0.000 0.000 1.000 0.000\n",
      "0.106 0.894 0.000 0.000\n",
      "0.000 1.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.191 0.809\n",
      "0.865 0.135\n",
      "0.339 0.661\n",
      "1.000 0.000\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n",
      "Iteration nr: 9\n",
      "A\n",
      "0.000 1.000 0.000 0.000\n",
      "0.000 0.000 1.000 0.000\n",
      "0.000 0.000 0.000 1.000\n",
      "1.000 0.000 0.000 0.000\n",
      " \n",
      "B\n",
      "0.800 0.200\n",
      "0.880 0.120\n",
      "0.000 1.000\n",
      "0.720 0.280\n",
      " \n",
      "Pi\n",
      "0.000\n",
      "0.000\n",
      "1.000\n",
      "0.000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy,hmm\n",
    "\n",
    "O = numpy.array([1,0,1,0,1,1,0,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1,0,1,1,0,0,1,1,\n",
    "                 0,0,0,1,0,0,0,1,1,0,0,1,0,0,1,1,0,0,0,1,0,1,0,1,0,0,0,1,0,\n",
    "                 0,0,1,0,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,\n",
    "                 0,1,1,1,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,1,0,0,1,0,1,1,\n",
    "                 1,0,0,0,1,1,0,0,1,0,1,1,1,0,0,1,1,0,0,0,1,1,0,0,1,1,0,0,1,\n",
    "                 0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,0,1,0,\n",
    "                 0,0,1,0,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,0,0,0,1,1,0,0])\n",
    "\n",
    "for i in range(10):\n",
    "    print 'Iteration nr: {}'.format(i)\n",
    "    hmmtoy = hmm.HMM(4,2)\n",
    "\n",
    "    for k in range(100):\n",
    "        hmmtoy.loaddata(O)\n",
    "        hmmtoy.forward()\n",
    "        hmmtoy.backward()\n",
    "        hmmtoy.learn()\n",
    "\n",
    "    print('A')\n",
    "    print(\"\\n\".join([\" \".join(['%.3f'%a for a in aa]) for aa in hmmtoy.A]))\n",
    "    print(' ')\n",
    "    print('B')\n",
    "    print(\"\\n\".join([\" \".join(['%.3f'%b for b in bb]) for bb in hmmtoy.B]))\n",
    "    print(' ')\n",
    "    print('Pi')\n",
    "    print(\"\\n\".join(['%.3f'%b for b in hmmtoy.Pi]))\n",
    "    print '\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "The beheavior is not consistent.\n",
    "\n",
    "In several iterations, the model learned a parameter $A$ that ensures the transition to a state different from the actual, i.e., $\\forall i, \\exists j \\neq i \\mid a_{ij} = 1$\n",
    "\n",
    "On the other hand, the parameter $B$, with some exceptions, was more consistently learned, changing generally only the row order between iterations. This parameter shows that the hidden states have a strong \"preference\" for either the symbol `1` or the symbol `0`, i.e., $\\forall i, b_{i0} > 0.6 \\vee b_{i1} > 0.6 $.\n",
    "\n",
    "Given that the solution is not stable, it's difficult to say what the parameters $(A, B)$ are explaining about $O$, beyond what was already said above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Question 1b: Finding the best number $N$ of hidden states (15 P)\n",
    "\n",
    "For the same sequence of observations as in Question 1a, we would like to determine automatically what is a good number of hidden states $N = \\mathrm{card}(S)$ for the model.\n",
    "\n",
    "* *Split* the sequence of observations into a training and test set (you can assume stationarity).\n",
    "* *Train* the model on the training set for several iteration (e.g. 100 iterations) and for multiple parameter $N$.\n",
    "* *Show* for each choice of parameter $N$ the log-probability $\\log p(O | \\lambda)$ for the test set. (If the results are unstable, perform several trials of the same experiment for each parameter $N$.)\n",
    "* *Explain* in the light of this experiment what is the best parameter $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1159674241655412e-75"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(markov_guy.A, markov_guy.B, markov_guy.Pi, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold nr: 0\n",
      "Training on fold nr: 1\n",
      "Training on fold nr: 2\n",
      "Training on fold nr: 3\n",
      "Training on fold nr: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.50164512e-013,   5.35782331e-014,   2.05155433e-018,\n",
       "          5.46767329e-016,   5.81572567e-016,   9.44332154e-016,\n",
       "          4.53474881e-028,   7.03207168e-020,   6.81586392e-046,\n",
       "          7.18604850e-018,   3.44500091e-033,   9.43140094e-063,\n",
       "          4.66590633e-045,   1.06483246e-024,   2.27084260e-059,\n",
       "          4.31313532e-034,   1.20909032e-030,   3.45473804e-157,\n",
       "          3.41893042e-070,   5.78267436e-044,   1.48076381e-065,\n",
       "          2.04494592e-061,   1.51797035e-041,   1.36879686e-024,\n",
       "          1.04354148e-083,   4.86841377e-074,   2.00970561e-098,\n",
       "          4.18405142e-084,   6.49931504e-049,   5.14481872e-088,\n",
       "          8.51997391e-084,   3.21420969e-063,   3.07575615e-068,\n",
       "          4.34038676e-142,   1.89136816e-106,   6.48247896e-080,\n",
       "          5.18447948e-101,   7.97581642e-083,   3.48055644e-062,\n",
       "          1.11396755e-042,   4.02126209e-064,   1.41537333e-098,\n",
       "          7.86813209e-064,   3.18501623e-115,   1.59166558e-071,\n",
       "          3.34627866e-061,   1.48157763e-112,   7.62576987e-064,\n",
       "          1.86246362e-049,   1.43518187e-077,   4.39087765e-081,\n",
       "          2.69496198e-092,   1.61053695e-168,   7.80924611e-099,\n",
       "          1.15278254e-071,   4.92164664e-074,   6.51328825e-075,\n",
       "          5.58190284e-068,   1.03609697e-099,   1.92175046e-114,\n",
       "          4.08706740e-118,   5.22256985e-068,   1.17735415e-065,\n",
       "          4.40981201e-053,   2.23851814e-064,   4.66872619e-067,\n",
       "          2.18898453e-110,   1.78561142e-052,   3.78322772e-187,\n",
       "          1.90652822e-309,   3.31459350e-139,   2.16401953e-105,\n",
       "          3.46381982e-053,   1.74323762e-061,   1.81793747e-089,\n",
       "          7.64193059e-093,   5.19784590e-073,   1.17254444e-164,\n",
       "          1.19059830e-150,   3.98835586e-053,   6.16257133e-107,\n",
       "          5.02548450e-049,   2.36600207e-063,   1.12091823e-076,\n",
       "          4.16256485e-069,   1.58197754e-063,   4.43254609e-091,\n",
       "          8.51582916e-078,   1.13038073e-286,   5.81475658e-054,\n",
       "          2.65212095e-107,   1.99069846e-098,   2.46766958e-129,\n",
       "          4.41112443e-084,   3.18027531e-078,   3.11395382e-098,\n",
       "          2.52392081e-071,   8.86685791e-073,   8.61780886e-102,\n",
       "          3.22994450e-067],\n",
       "       [  2.03511929e-012,   2.23937376e-012,   8.82263083e-013,\n",
       "          9.61902439e-013,   9.49310633e-014,   1.32918556e-014,\n",
       "          4.54779469e-014,   1.02963567e-013,   7.99901969e-019,\n",
       "          3.55633423e-016,   9.40037442e-026,   2.21932512e-017,\n",
       "          1.85974487e-019,   2.18782351e-017,   3.01224344e-030,\n",
       "          6.90874516e-016,   1.41174808e-035,   1.66110446e-025,\n",
       "          8.77070602e-019,   8.19232499e-032,   2.57750159e-018,\n",
       "          6.26866330e-018,   2.05256228e-020,   4.52274812e-021,\n",
       "          5.75580164e-030,   4.50851765e-032,   2.75158310e-025,\n",
       "          1.09892937e-028,   1.43704127e-031,   3.48646294e-025,\n",
       "          2.91789351e-024,   5.26327572e-031,   3.71239569e-039,\n",
       "          3.66054279e-033,   1.15881762e-035,   1.54790636e-036,\n",
       "          2.26588860e-033,   1.25711413e-025,   3.78021996e-025,\n",
       "          1.61381813e-041,   1.07594420e-022,   2.44786732e-038,\n",
       "          1.35736241e-047,   5.96552624e-027,   7.79701030e-059,\n",
       "          1.25460604e-037,   1.22621170e-025,   8.50584559e-028,\n",
       "          3.76086964e-031,   4.93891505e-029,   3.29478618e-035,\n",
       "          7.30924812e-033,   5.44805085e-043,   6.41106026e-016,\n",
       "          1.57700868e-029,   2.49832152e-032,   5.01430958e-042,\n",
       "          3.76254303e-033,   1.18512927e-035,   5.40520239e-030,\n",
       "          1.45564302e-037,   1.53869865e-020,   4.03006803e-042,\n",
       "          2.39478802e-025,   4.12710134e-030,   7.47779535e-024,\n",
       "          1.24269828e-030,   2.69624108e-040,   1.94353243e-018,\n",
       "          3.17436356e-025,   5.52007364e-021,   1.08258289e-036,\n",
       "          8.34712809e-021,   2.69843456e-023,   3.12759882e-019,\n",
       "          6.61588899e-020,   2.30449876e-021,   4.15066658e-022,\n",
       "          7.50745518e-028,   5.86942977e-021,   4.65512953e-027,\n",
       "          3.77507891e-030,   6.86393752e-031,   1.32275202e-022,\n",
       "          2.61911194e-028,   6.43987681e-031,   1.84553278e-028,\n",
       "          7.99712308e-024,   1.79661586e-032,   9.52273595e-021,\n",
       "          7.35922539e-021,   4.65646370e-020,   4.11900918e-025,\n",
       "          5.42446752e-044,   4.88185699e-032,   1.18088933e-028,\n",
       "          4.42341910e-027,   1.53972956e-022,   9.68057270e-028,\n",
       "          1.65307098e-018],\n",
       "       [  4.62175208e-013,   4.51280152e-013,   3.40211684e-014,\n",
       "          2.58485391e-015,   5.93324917e-014,   6.08915218e-014,\n",
       "          1.75343049e-014,   1.41974618e-019,   2.02920092e-021,\n",
       "          5.68927101e-025,   1.79510072e-015,   1.25077465e-031,\n",
       "          3.07275532e-021,   8.78779472e-028,   4.23305180e-021,\n",
       "          4.96754521e-031,   1.42542313e-065,   5.38378994e-041,\n",
       "          1.64365587e-034,   4.54636566e-023,   9.10811928e-022,\n",
       "          1.75996473e-071,   5.06337112e-024,   5.54949712e-029,\n",
       "          4.83067402e-034,   3.08027509e-030,   3.37037755e-038,\n",
       "          5.28526891e-068,   8.39405591e-059,   7.92853331e-058,\n",
       "          3.05817135e-067,   6.84849278e-025,   2.98883842e-044,\n",
       "          3.57403558e-030,   4.09105578e-047,   3.12235426e-025,\n",
       "          1.26173926e-031,   2.60445766e-024,   1.30275331e-120,\n",
       "          2.17777230e-057,   5.81594052e-022,   3.40600550e-051,\n",
       "          5.84074558e-026,   9.46088750e-044,   3.77062757e-023,\n",
       "          1.02158598e-027,   8.29343870e-023,   8.46510772e-025,\n",
       "          1.27020275e-022,   1.75109044e-025,   2.23601464e-029,\n",
       "          3.23841513e-026,   2.67209419e-025,   2.91254130e-024,\n",
       "          6.58252715e-027,   2.14136901e-027,   1.34508476e-023,\n",
       "          2.75129069e-026,   5.66462503e-022,   4.52751317e-026,\n",
       "          1.63805826e-032,   9.58148845e-025,   4.87919672e-024,\n",
       "          3.44527726e-026,   3.10989679e-032,   7.77719068e-025,\n",
       "          1.48149093e-025,   4.04277872e-023,   6.59039400e-029,\n",
       "          7.50603144e-024,   1.13458225e-023,   5.74288788e-024,\n",
       "          2.34692493e-025,   1.98944885e-030,   1.48114156e-021,\n",
       "          1.53426024e-023,   2.68463468e-024,   1.48638638e-024,\n",
       "          7.74099624e-026,   4.98386853e-025,   2.01508627e-026,\n",
       "          2.58657786e-028,   4.14486479e-024,   1.12475470e-023,\n",
       "          1.14252521e-025,   1.01922784e-024,   7.20290045e-042,\n",
       "          5.60371490e-024,   3.78947379e-025,   2.03776655e-044,\n",
       "          4.12213601e-025,   3.42763042e-025,   2.30304261e-025,\n",
       "          3.90758094e-025,   1.82921449e-025,   4.90358413e-025,\n",
       "          4.74561075e-025,   1.51265378e-026,   4.71071585e-026,\n",
       "          6.67736089e-025],\n",
       "       [  1.31746754e-012,   2.02900848e-015,   1.56335716e-013,\n",
       "          6.64594820e-014,   2.34714302e-014,   1.01807627e-014,\n",
       "          4.39756403e-016,   7.87559049e-017,   1.14571757e-018,\n",
       "          2.26332365e-016,   1.33339316e-022,   8.26335376e-025,\n",
       "          1.48096976e-046,   4.07774637e-025,   5.70109864e-041,\n",
       "          5.82983946e-033,   2.10753669e-041,   5.62493855e-040,\n",
       "          3.09112584e-032,   3.12847175e-029,   1.07793962e-084,\n",
       "          1.51013646e-031,   9.15068977e-046,   1.93643881e-059,\n",
       "          4.30781622e-033,   8.70845631e-046,   8.44307936e-050,\n",
       "          1.09756687e-063,   5.43273805e-083,   1.98867716e-054,\n",
       "          4.28227036e-046,   1.08891228e-129,   2.71716654e-040,\n",
       "          3.22428801e-069,   1.07463346e-072,   1.02565119e-091,\n",
       "          8.56106596e-060,   6.69025288e-139,   6.88105396e-053,\n",
       "          9.69309534e-137,   3.26949342e-093,   1.57901761e-051,\n",
       "          7.99344438e-076,   8.05407107e-053,   1.19505039e-069,\n",
       "          6.53250927e-083,   2.35608409e-032,   1.85468649e-034,\n",
       "          6.64303091e-043,   6.38456053e-073,   7.27620744e-067,\n",
       "          5.60142623e-023,   1.31032851e-078,   1.43527371e-139,\n",
       "          1.14141989e-168,   6.85743609e-085,   4.66368761e-071,\n",
       "          4.53131649e-089,   3.93065863e-091,   1.03209050e-051,\n",
       "          8.00102145e-078,   4.17217523e-043,   4.90899590e-056,\n",
       "          1.33147493e-085,   5.41267696e-064,   7.82828589e-048,\n",
       "          8.89516818e-066,   1.25318307e-101,   6.54114599e-051,\n",
       "          3.83766656e-055,   7.37008802e-057,   1.65877500e-094,\n",
       "          7.92179339e-044,   5.24903032e-102,   1.47100063e-054,\n",
       "          8.40656350e-061,   1.23693085e-110,   3.97849098e-070,\n",
       "          3.00156147e-029,   7.98073446e-046,   1.64751441e-076,\n",
       "          3.47691748e-044,   8.21134363e-107,   4.74136803e-066,\n",
       "          3.65688526e-067,   1.51985271e-079,   8.89855046e-066,\n",
       "          4.23301342e-055,   3.35504512e-067,   1.28998472e-039,\n",
       "          7.63957971e-046,   1.44126606e-040,   7.00416209e-051,\n",
       "          5.82640999e-078,   6.52809019e-068,   7.12886367e-046,\n",
       "          1.72052325e-071,   4.33260413e-054,   2.18228582e-058,\n",
       "          6.76337886e-132],\n",
       "       [  4.62175208e-013,   3.91405456e-013,   1.23336452e-014,\n",
       "          2.07408138e-013,   8.64516787e-015,   1.68879165e-015,\n",
       "          5.35934939e-020,   3.84649550e-015,   5.39958949e-020,\n",
       "          1.56024957e-027,   2.93067802e-075,   1.32531176e-047,\n",
       "          2.94120669e-039,   5.74221592e-018,   7.20607434e-033,\n",
       "          2.47258109e-023,   2.36343944e-051,   5.51461389e-031,\n",
       "          6.20831066e-072,   1.09439354e-038,   7.00931759e-027,\n",
       "          9.03121906e-055,   2.61435531e-026,   1.87109397e-038,\n",
       "          6.23276019e-039,   1.24948765e-128,   2.67194039e-024,\n",
       "          1.28767410e-141,   1.31840378e-053,   9.86272776e-024,\n",
       "          8.91244039e-040,   8.59822307e-040,   3.12163338e-043,\n",
       "          1.59177162e-039,   3.53192559e-040,   4.24231481e-053,\n",
       "          2.17034682e-035,   6.21208948e-036,   1.27843603e-056,\n",
       "          2.82435031e-043,   3.35377489e-028,   6.45365143e-028,\n",
       "          1.19213492e-031,   4.47415366e-038,   1.98767346e-027,\n",
       "          4.13043602e-039,   7.45531013e-030,   4.37251960e-042,\n",
       "          1.75499912e-047,   2.87051997e-061,   8.04228329e-080,\n",
       "          1.33704006e-065,   1.07452924e-069,   2.21193594e-036,\n",
       "          4.13077390e-029,   1.29322575e-077,   1.98664302e-068,\n",
       "          3.75566324e-060,   5.01944272e-036,   1.38949280e-090,\n",
       "          1.95715812e-051,   1.69090277e-034,   1.71403742e-048,\n",
       "          1.49794150e-049,   1.06648249e-032,   5.08104993e-043,\n",
       "          3.01801668e-053,   6.24395081e-029,   7.82642569e-032,\n",
       "          3.38525470e-036,   1.00373809e-037,   2.00526235e-060,\n",
       "          1.72682051e-103,   3.37648538e-117,   2.87923734e-032,\n",
       "          1.02535209e-042,   1.66862296e-043,   1.46645914e-062,\n",
       "          1.33558425e-051,   3.79825071e-035,   7.36826693e-045,\n",
       "          8.87051785e-043,   2.59259001e-031,   1.57053371e-030,\n",
       "          1.43008315e-035,   3.68576972e-039,   1.83834529e-052,\n",
       "          1.64952996e-051,   2.55680198e-046,   1.83104387e-029,\n",
       "          3.70802675e-032,   7.74036303e-045,   9.13103639e-098,\n",
       "          3.77556974e-030,   9.73195790e-037,   6.27810575e-033,\n",
       "          9.31899057e-049,   1.41540780e-046,   1.96729133e-040,\n",
       "          1.19599790e-044]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(A, B, Pi, O):\n",
    "    # Initialization\n",
    "    Z = numpy.array([B[:, O[t]] for t in range(len(O))])\n",
    "    alpha = numpy.empty([len(O), len(Pi)])\n",
    "    alpha[:] = numpy.NaN\n",
    "    alpha[0] = Pi * Z[0]\n",
    "        \n",
    "    # Induction\n",
    "    for t in range(len(O)-1):\n",
    "        alpha[t + 1] = numpy.dot(alpha[t], A) * Z[t + 1]\n",
    "        \n",
    "    # Termination\n",
    "    return alpha[-1].sum()\n",
    "\n",
    "\n",
    "L = O.shape[0]\n",
    "o_idx = numpy.arange(L)\n",
    "train_size = int(L * 0.8)\n",
    "folds = []\n",
    "folds_nr = 5\n",
    "# Generate cross validation folds\n",
    "for i in range(folds_nr):\n",
    "    train_idx = numpy.random.choice(o_idx, train_size, replace=False)\n",
    "    test_idx = numpy.array(list(set(o_idx) - set(train_idx)))\n",
    "    train = O[train_idx]\n",
    "    test = O[test_idx]\n",
    "    folds.append((train, test))\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "result = numpy.zeros((folds_nr, epochs))\n",
    "for i, fold in enumerate(folds):\n",
    "    print \"Training on fold nr: {}\".format(i)\n",
    "    train, test = fold\n",
    "    for n in range(1, epochs + 1):\n",
    "        markov_guy = hmm.HMM(n, 2)\n",
    "        for k in range(100):\n",
    "            markov_guy.loaddata(train)\n",
    "            markov_guy.forward()\n",
    "            markov_guy.backward()\n",
    "            markov_guy.learn()\n",
    "        result[i, n - 1] = forward(markov_guy.A, markov_guy.B, markov_guy.Pi,test)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -29.01665765,  -30.55763351,  -40.72793396,  -35.14250832,\n",
       "         -35.08079592,  -34.59605371,  -62.96061291,  -44.10122051,\n",
       "        -103.99966145,  -39.47439024,  -74.7483839 , -142.81881621,\n",
       "        -102.07604709,  -55.19922476, -135.03236953,  -76.82622807,\n",
       "         -68.88768452, -360.26611297, -159.95162875,  -99.55887782,\n",
       "        -149.275473  , -139.74231933,  -93.98861467,  -54.94811008,\n",
       "        -191.07194252, -168.80852871, -224.95535087, -191.98586779,\n",
       "        -110.95497276, -200.98949805, -191.27473453, -143.89527935,\n",
       "        -155.45223555, -325.49911975, -243.4367194 , -182.33770445,\n",
       "        -230.91542494, -189.0381487 , -141.51308359,  -96.60064589,\n",
       "        -145.97385015, -225.30594578, -145.30262526, -263.63882831,\n",
       "        -163.0187606 , -139.24984179, -257.49642293, -145.33391267,\n",
       "        -112.20476942, -176.93776058, -185.02986341, -210.84644446,\n",
       "        -386.35772799, -225.90061578, -163.34136298, -168.79765372,\n",
       "        -170.82003754, -154.85625659, -227.92046347, -261.84146413,\n",
       "        -270.29721328, -154.92279674, -149.50476137, -120.55317787,\n",
       "        -146.55963185, -152.73231496, -252.50092248, -119.15466395,\n",
       "        -429.25283485, -710.85350984, -318.86099293, -240.99946738,\n",
       "        -120.79463795, -139.90194659, -204.33237068, -212.10676338,\n",
       "        -166.4404675 , -377.46477913, -345.21330799, -120.65363085,\n",
       "        -244.55811084, -111.21214769, -144.20165922, -174.88231887,\n",
       "        -157.45223998, -144.60418519, -208.04626931, -177.45971057,\n",
       "        -658.41678209, -122.5791961 , -245.40124527, -224.96485355,\n",
       "        -296.13020278, -191.93301818, -178.44466948, -224.51744587,\n",
       "        -162.55772804, -165.90639129, -232.70984863, -153.10073628],\n",
       "       [ -26.92046668,  -26.82482486,  -27.7562861 ,  -27.66986336,\n",
       "         -29.98562542,  -31.9516249 ,  -30.72154887,  -29.90440119,\n",
       "         -41.66979777,  -35.57263118,  -57.6264629 ,  -38.34674343,\n",
       "         -43.12867745,  -38.36103936,  -67.97486766,  -34.90857346,\n",
       "         -80.24564954,  -57.05714461,  -41.57769946,  -71.57952524,\n",
       "         -40.49971112,  -39.61096853,  -45.33261295,  -46.84516715,\n",
       "         -67.32734446,  -72.17675456,  -56.55245091,  -64.3780462 ,\n",
       "         -71.01755156,  -56.31573959,  -54.19118028,  -69.71938429,\n",
       "         -88.48914122,  -74.68769663,  -80.44307807,  -82.45616007,\n",
       "         -75.16734107,  -57.33580861,  -56.23484513,  -93.92738593,\n",
       "         -50.58367345,  -86.60301637, -107.91595596,  -60.38380024,\n",
       "        -133.79878012,  -84.96882683,  -57.36069783,  -62.33162896,\n",
       "         -70.05548767,  -65.17782202,  -79.39813698,  -73.99616766,\n",
       "         -97.3159011 ,  -34.98333682,  -66.31943789,  -72.76710386,\n",
       "         -95.09627817,  -74.660213  ,  -80.42062639,  -67.39019089,\n",
       "         -84.8202007 ,  -45.62076484,  -95.31479065,  -56.69133261,\n",
       "         -67.65997748,  -53.25010422,  -68.86026774,  -91.11154511,\n",
       "         -40.78202451,  -56.40952017,  -46.64589575,  -82.8137136 ,\n",
       "         -46.23236941,  -51.96678533,  -42.60885121,  -44.16222768,\n",
       "         -47.51942376,  -49.2336031 ,  -62.45648605,  -46.58452947,\n",
       "         -60.63182777,  -67.7491315 ,  -69.45385662,  -50.37715761,\n",
       "         -63.5095473 ,  -69.51762847,  -63.8596146 ,  -53.18296037,\n",
       "         -73.09681816,  -46.10060476,  -46.35833227,  -44.51344556,\n",
       "         -56.14901468,  -99.62282435,  -72.0971973 ,  -64.30611478,\n",
       "         -60.68288456,  -50.22526525,  -62.20226154,  -40.94389692],\n",
       "       [ -28.40283234,  -28.42668807,  -31.01179346,  -33.5891074 ,\n",
       "         -30.45561932,  -30.42968245,  -31.67461715,  -43.39863866,\n",
       "         -47.64664487,  -55.8260452 ,  -33.95371526,  -71.1563748 ,\n",
       "         -47.2317123 ,  -62.29901881,  -46.91136375,  -69.77721209,\n",
       "        -149.31356234,  -92.72259624,  -77.79097021,  -51.44512898,\n",
       "         -48.4477058 , -162.91824784,  -53.64000974,  -65.06126038,\n",
       "         -76.71290716,  -67.95253388,  -86.28320876, -154.91086282,\n",
       "        -133.72499666, -131.47946733, -153.15538409,  -55.64059873,\n",
       "        -100.21885927,  -67.80385742, -106.8126963 ,  -56.42604004,\n",
       "         -71.14764675,  -54.30481777, -276.0457312 , -130.46904783,\n",
       "         -48.89626953, -116.20629954,  -58.10235396,  -99.0665779 ,\n",
       "         -51.63221569,  -62.14844121,  -50.84399246,  -55.42867458,\n",
       "         -50.41769551,  -57.00438862,  -65.97027259,  -58.69212837,\n",
       "         -56.58176482,  -54.19301623,  -60.28537877,  -61.40835216,\n",
       "         -52.66300011,  -58.85514228,  -48.92263134,  -58.3570396 ,\n",
       "         -73.18921142,  -55.30479437,  -53.67706163,  -58.63020803,\n",
       "         -72.54813344,  -55.51343215,  -57.17157836,  -51.56252488,\n",
       "         -64.88935456,  -53.24633534,  -52.83319262,  -53.51408003,\n",
       "         -56.71152139,  -68.38969515,  -47.96147384,  -52.5314088 ,\n",
       "         -54.27449757,  -54.8656943 ,  -57.82068203,  -55.95842092,\n",
       "         -59.16655041,  -63.52204689,  -53.84017206,  -52.84189217,\n",
       "         -57.43138642,  -55.24299691,  -94.73409012,  -53.53861248,\n",
       "         -56.23240016, -100.60188971,  -56.14825585,  -56.33275814,\n",
       "         -56.7303962 ,  -56.20170883,  -56.96074069,  -55.97466093,\n",
       "         -56.00740719,  -59.45334684,  -58.31737254,  -55.66590449],\n",
       "       [ -27.35530976,  -33.83122915,  -29.48677067,  -30.34218393,\n",
       "         -31.38299245,  -32.21827646,  -35.36031073,  -37.08017842,\n",
       "         -41.31050053,  -36.02452711,  -50.36914511,  -55.4527968 ,\n",
       "        -105.52621716,  -56.15908285,  -92.66532991,  -74.2223186 ,\n",
       "         -93.66046899,  -90.3761937 ,  -72.5541876 ,  -65.63442307,\n",
       "        -193.34209635,  -70.96793786, -103.70508502, -135.19166986,\n",
       "         -74.52487697, -103.75461973, -112.99590755, -144.96976506,\n",
       "        -189.42211947, -123.65212535, -104.46443095, -296.94829771,\n",
       "         -91.1038141 , -157.70765926, -165.71414706, -209.50991575,\n",
       "        -136.00788087, -318.15867625, -120.1082381 , -313.18274393,\n",
       "        -212.95577859, -116.97503685, -172.91784531, -119.95083224,\n",
       "        -158.70018306, -189.23777158,  -72.82572202,  -77.67017749,\n",
       "         -97.11759068, -166.23482913, -152.28859146,  -51.23643589,\n",
       "        -179.33135938, -319.69797236, -386.70202262, -193.79439928,\n",
       "        -161.94373514, -203.41906076, -208.16643646, -117.40025339,\n",
       "        -177.52206804,  -97.58272146, -127.35369579, -195.43344561,\n",
       "        -145.67670216, -108.46634089, -149.78510791, -232.33540762,\n",
       "        -115.55372736, -125.2973156 , -129.24992065, -215.93691936,\n",
       "         -99.24412647, -233.20563613, -123.95365215, -138.3286779 ,\n",
       "        -253.07172704, -159.80005391,  -65.67583505, -103.84188383,\n",
       "        -174.49719933, -100.06759797, -244.27108838, -150.41429043,\n",
       "        -152.97658947, -181.48560892, -149.78472774, -125.19926598,\n",
       "        -153.06273601,  -89.54618826, -103.88557169,  -91.73788179,\n",
       "        -115.48533519, -177.83923623, -154.69967189, -103.95476243,\n",
       "        -162.94091314, -122.87342625, -132.76956253, -302.02970968],\n",
       "       [ -28.40283234,  -28.5690324 ,  -32.02644549,  -29.20408786,\n",
       "         -32.38177586,  -34.01476312,  -44.37285927,  -33.19161392,\n",
       "         -44.36537893,  -61.72495172, -171.61864817, -107.93985165,\n",
       "         -88.72199869,  -39.69868649,  -74.01038374,  -52.05419456,\n",
       "        -116.5717218 ,  -69.67273624, -163.96023787,  -87.40803317,\n",
       "         -60.22255716, -124.44149276,  -58.90619488,  -86.87171026,\n",
       "         -87.97099934, -294.50815832,  -54.27923729, -324.41166054,\n",
       "        -121.76058818,  -52.97327945,  -89.91595562,  -89.95184816,\n",
       "         -97.87280262,  -89.335971  ,  -90.8415605 , -120.59190086,\n",
       "         -79.81559127,  -81.06656604, -128.69912772,  -97.97288064,\n",
       "         -63.26229606,  -62.60773652,  -71.20439213,  -85.99991633,\n",
       "         -61.48283267,  -88.38243565,  -67.06862624,  -95.2332345 ,\n",
       "        -107.65903101, -139.40319748, -182.1220944 , -149.37757279,\n",
       "        -158.80648877,  -82.09919523,  -65.35650292, -177.04191248,\n",
       "        -155.88934003, -136.83184068,  -81.27974443, -206.90371958,\n",
       "        -116.76034626,  -77.76263059, -109.98523281, -112.42257773,\n",
       "         -73.61835713,  -97.38564108, -120.93241004,  -64.94335457,\n",
       "         -71.62521706,  -81.6736342 ,  -85.19191732, -137.45933068,\n",
       "        -236.61998272, -268.18562054,  -72.62519753,  -96.68353785,\n",
       "         -98.49916029, -142.37742502, -117.14247091,  -79.25593763,\n",
       "        -101.61914666,  -96.82842582,  -70.4274805 ,  -68.62613728,\n",
       "         -80.23274567,  -88.49633924, -119.12555897, -116.93134937,\n",
       "        -104.98015703,  -66.17008147,  -72.37222311, -101.56988059,\n",
       "        -223.44165991,  -67.74900149,  -82.92023334,  -74.14823977,\n",
       "        -110.59461524, -105.57149659,  -91.42674608, -101.13476319]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_result = numpy.log(result)\n",
    "log_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best N: 1.\n",
      "Corresponding median (over CV folds) logp(O): -28.4028323372\n",
      "Corresponding median (over CV folds) p(O): 4.62175208181e-13\n"
     ]
    }
   ],
   "source": [
    "median_logp = numpy.median(log_result, axis=0)\n",
    "median_p = numpy.median(result, axis=0)\n",
    "max_logp = numpy.argmax(median_logp)\n",
    "print(\"Best N: {}.\"\n",
    "      \"\\nCorresponding median (over CV folds) logp(O): {}\"\n",
    "      \"\\nCorresponding median (over CV folds) p(O): {}\".format(\n",
    "            max_logp + 1, median_logp[max_logp], median_p[max_logp]\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Text modeling and generation (30 P)\n",
    "\n",
    "We would like to train an HMM on character sequences taken from English text. We use the 20 newsgroups dataset that is accessible via scikits-learn http://scikit-learn.org/stable/datasets/twenty_newsgroups.html. (For this, you need to install scikits-learn if not done already.) Documentation is available on the website. The code below allows you to (1) read the dataset, (2) sample HMM-readable sequences from it, and (3) convert them back into string of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Download a subset of the newsgroup dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',categories=['sci.med'])\n",
    "newsgroups_test  = fetch_20newsgroups(subset='test' ,categories=['sci.med'])\n",
    "\n",
    "# Sample a sequence of T characters from the dataset\n",
    "# that the HMM can read (0=whitespace 1-26=A-Z).\n",
    "#\n",
    "# Example of execution:\n",
    "# O = sample(newsgroups_train.data)\n",
    "# O = sample(newsgroups_test.data)\n",
    "#\n",
    "def sample(data,T=50):\n",
    "    i = numpy.random.randint(len(data))\n",
    "    O = data[i].upper().replace('\\n',' ')\n",
    "    O = numpy.array([ord(s) for s in O])\n",
    "    O = numpy.maximum(O[(O>=65)*(O<90)+(O==32)]-64,0)\n",
    "    j = numpy.random.randint(len(O)-T)\n",
    "    return O[j:j+T]\n",
    "\n",
    "# Takes a sequence of integers between 0 and 26 (HMM representation)\n",
    "# and converts it back to a string of characters\n",
    "def tochar(O):\n",
    "    return \"\".join([\"%s\"%chr(o) for o in (O+32*(O==0)+64*(O>0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a (15 P)\n",
    "\n",
    "In order to train the HMM, we use a stochastic optimization algorithm where the Baum-Welch procedure is applied to randomly drawn sequences of $T=50$ characters at each iteration. The HMM has 27 visible states (A-Z + whitespace) and 200 hidden states. Because the Baum-Welch procedure optimizes for the sequence taken as input, and no necessarily the full text, it can take fairly large steps in the parameter space, which is inadequate for stochastic optimization. We consider instead for the parameters $\\lambda = (A,B,\\Pi)$ the update rule $\\lambda^{new} = (1-\\gamma) \\lambda + \\gamma \\bar \\lambda$, where $\\bar \\lambda$ contains the candidate parameters obtained from Equations 40a-c. A reasonable value for $\\gamma$ is $0.1$.\n",
    "\n",
    "* *Create* a new class `HMMChar` that extends the class `HMM` provided in `hmm.py`.\n",
    "* *Implement* for this class a new method `HMMchar.learn(self)` that overrides the original methods, and implements the proposed update rule instead.\n",
    "* *Implement* the stochastic training procedure and run it.\n",
    "* *Monitor* $\\log p(O|\\lambda)$ on the test set at multiple iterations for sequences of same length as the one used for training. (Hint: for less noisy log-probability estimates, use several sequences or a moving average.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-162.10062251, -156.580757  , -156.09755696, -151.15650923,\n",
       "       -150.16632562, -149.522913  , -153.0994435 , -149.69479725,\n",
       "       -145.26376158, -150.73024066, -148.73867015, -154.77751895,\n",
       "       -143.37566415, -142.97677509, -144.54481893, -134.68602492,\n",
       "       -146.90470661, -149.5882919 , -148.95227357, -140.75975492,\n",
       "       -140.98639013, -148.09081874, -145.8297605 , -145.22869217,\n",
       "       -148.56791964, -138.20774599, -143.78076937, -140.39063153,\n",
       "       -131.59056417, -145.08543598, -149.37908783, -141.89485938,\n",
       "       -111.98991447, -143.07721399, -136.83723701, -148.84195832,\n",
       "       -141.7326714 , -146.83664151, -141.37673283, -139.92763161,\n",
       "        -97.83790217, -155.44510494, -137.99978625, -139.76884504,\n",
       "       -136.4191746 , -149.46230115, -140.16123093, -140.45278159,\n",
       "       -136.35888852, -150.36278061, -133.59425922, -141.54617982,\n",
       "       -130.7475347 , -139.25002393, -145.04625481, -138.86762523,\n",
       "       -159.68170565, -155.09928778, -146.59798147, -140.53927185,\n",
       "       -137.64603116, -135.55993487, -144.71637582, -142.78336301,\n",
       "       -146.08216967, -146.39490825, -138.61988474, -126.54656209,\n",
       "       -128.3442678 , -136.48119027, -137.20848139, -140.611005  ,\n",
       "       -146.26836239, -141.92351608, -134.9290404 , -127.52255306,\n",
       "       -144.33372456, -137.27054282, -141.61328081, -146.84921766,\n",
       "       -136.7172564 , -127.21394262, -147.58983703, -145.05762351,\n",
       "       -131.7865502 , -141.63394273, -135.81950346, -131.29601488,\n",
       "       -144.94013889, -149.20165033, -110.25277244, -142.68090381,\n",
       "       -151.44907554, -133.88151651, -131.26489293, -131.61312532,\n",
       "       -140.22820927, -134.34911018, -149.71612234, -125.71849696])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hmm import HMM\n",
    "na = numpy.newaxis\n",
    "\n",
    "class HMMChar(hmm.HMM):\n",
    "\n",
    "    def learn(self,param):\n",
    "        # Compute gamma\n",
    "        self.gamma = self.alpha*self.beta / self.pobs\n",
    "        \n",
    "        # Compute xi and psi\n",
    "        self.xi = self.alpha[:-1,:,na]*self.A[na,:,:]*self.beta[1:,na,:]*self.Z[1:,na,:] / self.pobs\n",
    "        self.psi = self.gamma[:,:,na]*(self.O[:,na,na] == numpy.arange(self.B.shape[1])[na,na,:])\n",
    "        \n",
    "        # Update HMM parameters\n",
    "        self.A  = param*(self.xi.sum(axis=0)  / self.gamma[:-1].sum(axis=0)[:,na])+(1-param)*self.A\n",
    "        self.B  = param*(self.psi.sum(axis=0) / self.gamma.sum(axis=0)[:,na])+(1-param)*self.B\n",
    "        self.Pi = param*(self.gamma[0])+(1-param)*self.Pi\n",
    "\n",
    "    def generate(self, T):\n",
    "        N = numpy.arange(self.Pi.shape[0])\n",
    "        M = numpy.arange(self.B.shape[1])\n",
    "        states = numpy.zeros(T)\n",
    "        symbols = numpy.zeros(T, dtype=int)\n",
    "        states[0] = numpy.random.choice(N, size=1, p=self.Pi)\n",
    "        symbols[0] = numpy.random.choice(M, size=1, p=self.B[states[0],:])\n",
    "        for s in range(1, T):\n",
    "            states[s] = numpy.random.choice(N, size=1, p=self.A[states[s-1], :])\n",
    "            symbols[s] = numpy.random.choice(M, size=1, p=self.B[states[s], :])\n",
    "        return symbols\n",
    "\n",
    "\n",
    "hmmchar = HMMChar(200, 27)\n",
    "trainsample = lambda: sample(newsgroups_train.data)\n",
    "testsample  = lambda: sample(newsgroups_test.data)\n",
    "\n",
    "def question2a(hmmchar, trainsample, testsample, iterations=100):\n",
    "    result = numpy.zeros(iterations)\n",
    "    for k in range(iterations):\n",
    "        hmmchar.loaddata(trainsample())\n",
    "        hmmchar.forward()\n",
    "        hmmchar.backward()\n",
    "        hmmchar.learn(0.1)\n",
    "        result[k] = numpy.log(forward(hmmchar.A, hmmchar.B, hmmchar.Pi, testsample()))\n",
    "    return result\n",
    "\n",
    "question2a(hmmchar, trainsample, testsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b (15 P)\n",
    "\n",
    "In order to visualize what the HMM has learned, we would like to generate random text from it. A well-trained HMM should generate character sequences that have some similarity with the text it has been trained on.\n",
    "\n",
    "* *Implement* a method `generate(self,T)` of the class `HMMChar` that takes as argument the length of the character sequence that has to be generated.\n",
    "* *Test* your method by generating a sequence of 250 characters and comparing it with original text and a purely random sequence.\n",
    "* *Discuss* how the generated sequences compare with written English and what are the advantages and limitations of the HMM for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "YS OBVIOUSLY I WOULD REIMBURSE FOR YOU ALL POSTAGE AND RELATED CHARGES FAILING THAT IT WOULD BE BENEFICIAL IF ANYONE COULD POINT TO ANY LIBRARY IN THE NY NJ OR PA AREA THAT MAY HAVE THESE BOOKS  PLEASE RESPOND BY EMAIL SINCE I DO NOT READ THIS NEWSGR\n",
      "\n",
      "learned:\n",
      "P BL JTOCHMM ULHEAOAXNR YLDHECE YOSITAOSTRN P M COTENGLSSNT C IRSINSTHY UEHLCTSTOE  WRWO S WRDE TUY WAT DYEN IT LURHSCRE  ENCTEYMM E ORSR ALOCO  OLGDA WH  EWAF SE Y KOENE ES LO ESOTHRDYA AREAI LES W ENP AWII O  ECHEN ECWCHIN ADI AGENDNPMELRH  BRENJAE\n",
      "\n",
      "random:\n",
      "FHBCRJRJBANVJCKDIJNWJOHBZGJLBRVYPZONXUCUIEKRVLYSXESOTEQDUYCTKTUNSJVLEABVNZROEVWIGH CDTCYVAZKIDJPKDNQUAP VRX WQWOBIRPHT PGBNVTVUPMZHBZLKBX EZHHLWAFVHSO MQSUTELQLMNRPNNVLCN FCTDFULAZQ YBBKF DOFUPLJSJNGMARQDDIFSPXYMJQWL AGQUWKHJCURZTXLQZKXNKIGYIJJDENFXB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:25: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/mtambos/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/mtambos/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "print(\"original:\\n\"+tochar(sample(newsgroups_test.data, T=250)))\n",
    "print(\"\\nlearned:\\n\"+tochar(hmmchar.generate(250)))\n",
    "print(\"\\nrandom:\\n\" +tochar(numpy.random.choice(27, size=250)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "Although no real english words were generated, in general the word length seems to be reasonable (although it looks like there's a preference for longer words).\n",
    "\n",
    "The spaces also look right, since there are only a few cases with more than one space between words.\n",
    "\n",
    "In contrast, the randomly generated sequence generated many more overly long words.\n",
    "\n",
    "Maybe one solution for generating passable english senteces could be to use words as symbols instead of characters. However, this would imply several orders of magnitude more symbols.\n",
    "\n",
    "Another experiment using 10 times as many states and training for 5 times as many iterations (see below) show some plausible words (`ON`, `WAR`, `THE`, `SARGE`, etc.). This suggest that  the HMM is capturing some of the structure in the corpus.\n",
    "\n",
    "As configured, the HMM does not perform well for the task of generating plausible english words.\n",
    "One advantage of it is that it's relatively simple to have an idea of how a string was generated (by backtracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:25: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/mtambos/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:27: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/mtambos/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('learned:\\n',\n",
       " ' LT MOLD SIRATOLDSORBOTERTS SIL TONHI DKO AUSTS PEANY ON ART TOMGARKEW WAR TOMEAME CHE TARANT THE TOLH THABEIMY  SAGROSUTS ARAS THE SO EWEPSTECUUTE ITITHEK COTHONS SORSY PELTOYLS TRER EVE INK TO TA S IN IN O QTEA SARGE SANT THOWO CITAS OF LS SYR EAK ')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmmchar = HMMChar(2000, 27)\n",
    "trainsample = lambda: sample(newsgroups_train.data)\n",
    "testsample  = lambda: sample(newsgroups_test.data)\n",
    "\n",
    "question2a(hmmchar, trainsample, testsample, 500)\n",
    "\"learned:\\n\", tochar(hmmchar.generate(250))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
