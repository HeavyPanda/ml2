\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\pagestyle{plain}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{eurosym}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{dlfltxbcodetips}
\usepackage{cancel}

%    \usepackage{tkz-graph}  
%    \usetikzlibrary{shapes.geometric}%   
% 	 \usetikzlibrary{bayesnet}
	
\input{preamble.tex} % import config
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}  
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\vivid}{\stackrel{\text{vivid}}{=}}
\newcommand{\icol}[1]{% inline column vector
  \left(\begin{smallmatrix}#1\end{smallmatrix}\right)%
}

\newcommand\indep{\protect\mathpalette{\protect\indeP}{\perp}}
\def\indeP#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\newcommand{\mlq}{F(\q)}
\newcommand{\si}{s}
\newcommand{\sj}{{s'}}
\newcommand{\p}{p}
\newcommand{\q}{r}
\newcommand{\z}{w}
%\newcommand{\x}{\mathcal{D}}
%\newcommand{\mlq}{-L(\q)}
%\newcommand{\si}{i}
%\newcommand{\sj}{j}
%\newcommand{\p}{p}
%\newcommand{\q}{q}
%\newcommand{\z}{Z}
%\newcommand{\x}{X}

\newcommand{\pxgz}{\p(\x|\z)}
\newcommand{\pzgx}{\p(\z|\x)}
\newcommand{\pxz}{\p(\x,\z)}
\newcommand{\px}{\p(\x)}

\newcommand{\qz}{\q(\z)}
\newcommand{\qi}{\q_\si}
\newcommand{\qj}{\q_\sj}
\newcommand{\qk}{\q_k}
\newcommand{\pz}{\p(\z)}
\newcommand{\pzi}{\p(\z_\si)}
\newcommand{\pzj}{\p(\z_\sj)}
\newcommand{\pzk}{\p(\z_k)}

\newcommand{\sigm}{\text{sigm}}

\newcommand{\zi}{\z_\si}
\newcommand{\zj}{\z_\sj}
\newcommand{\zk}{\z_k}
\newcommand{\dz}{\mathrm{d}\z}
\newcommand{\dzi}{\mathrm{d}\z_\si}
\newcommand{\dzj}{\mathrm{d}\z_\sj}
\newcommand{\dzk}{\mathrm{d}\z_k} 

\newcommand{\E}{\mathbb{E}}





%\newcommand{\propq}{ \underset{ \text{wrt.}\put(1,1){\scriptsize *}q }{\propto} }

\newcommand{\eqs}[1]{ \stackrel{#1}{=}  }
\newcommand{\eqq}{  \overset{\text{!}}{=} }
\newcommand{\propqz}{ \underset{ \overset{\text{wrt.}}{\qz} }{\propto} }
\newcommand{\propz}{ \underset{ \overset{\text{wrt.}}{\z} }{\propto} }
\newcommand{\propzj}{ \underset{ \overset{\text{wrt.}}{\zj} }{\propto} }
%\newcommand{\constw}{ \underset{ \text{ wrt. \w} }{\text{ const}} }
%\newcommand{\consty}{ \underset{ \text{ wrt. \y} }{\text{ const}} }
\newcommand{\const}[1]{{\underset{ \text{ wrt. #1} }{\text{ const}} }}

\newcommand{\tr}[1]{{#1^\top}}
\newcommand{\inv}[1]{{#1^{-1}}}
\newcommand{\trk}[1]{{(#1)^\top}}
\newcommand{\invk}[1]{{(#1)^{-1}}}
\newcommand{\tin}[1]{{(#1^\top)^{-1}}}

\newcommand{\Yt}{{Y^\top}}
\newcommand{\Xt}{{X^\top}}
\newcommand{\xt}{{\x^\top}}
\newcommand{\yt}{{\y^\top}}
\newcommand{\Wt}{{\W^\top}}
\newcommand{\w}{w}
\newcommand{\lx}{{\lambda_{x}}}
\newcommand{\ly}{{\lambda_{y}}}
\newcommand{\rhi}{{r^{(i)}}}
\newcommand{\rhj}{{r^{(j)}}}
\newcommand{\xhi}{{x^{(i)}}}
\newcommand{\shi}{{s^{(i)}}}
\newcommand{\xhj}{{x^{(j)}}}
\newcommand{\shj}{{s^{(j)}}}
\newcommand{\Wi}{{W_{i}}}
\newcommand{\Wj}{{W_{j}}}
\newcommand{\Wit}{W_{i}^\top}
\newcommand{\Wjt}{W_{j}^\top}
\newcommand{\Wij}{W_{ij}}
\newcommand{\Wlk}{W_{lk}}
\newcommand{\ax}{{\alpha_{x}}}
\newcommand{\ay}{{\alpha_{y}}}
\newcommand{\axt}{\alpha_{x}^\top}
\newcommand{\ayt}{\alpha_{y}^\top}
\newcommand{\Cxx}{C_{xx}}
\newcommand{\Cxy}{C_{xy}}
\newcommand{\Cyx}{C_{yx}} 
\newcommand{\Cyy}{C_{yy}}
\newcommand{\1}{\mathds{1}}
\newcommand{\lag}{\mathcal{L}}


\begin{document}

% header configuration
\title{\b{Exercise Sheet 6}}
\author{Machine Learning 2, SS16}

\maketitle

% authors
Mario Tambos, 380599;\quad Viktor Jeney, 348969;\quad Sascha Huk, 321249;\quad Jan Tinapp, 0380549\\


\extitle{Exercise 1}
\textbf{(a)}\\
Define
\[ y:=x^TW-b^T \]
\begin{align*}
p_{\theta}(x)&=\sum_{h\in\{-1,0,1\}^N}p(x,h)\\
&=\sum_{h\in\{-1,0,1\}^N}\frac{1}{Z}\exp(yh+x^Ta)\\
&=\frac{1}{Z}\exp(x^Ta)\sum_{h\in\{-1,0,1\}^N}\exp(yh)\\
&=\frac{1}{Z}\exp(x^Ta)\sum_{h\in\{-1,0,1\}^N}\exp(\sum_{i=1}^{N}y_ih_i)\\
&=\frac{1}{Z}\exp(x^Ta)\sum_{h\in\{-1,0,1\}^N}\prod_{i=1}^{N}\exp(y_ih_i)\\
\end{align*}
Because the expression $\exp(y_ih_i)$ only depends on the i'th component of h, we can rewrite the sum and product to get:
\begin{align*}
p_{\theta}(x)&=\frac{1}{Z}\exp(x^Ta)\prod_{i=1}^{N}\sum_{h\in\{-1,0,1\}}\exp(y_ih_i)\\
&=\frac{1}{Z}\exp(x^Ta)\exp(\log(\prod_{i=1}^{N}\sum_{h\in\{-1,0,1\}}\exp(y_ih_i)))\\
&=\frac{1}{Z}\exp(x^Ta)\exp(\sum_{i=1}^{N}\log(\sum_{h\in\{-1,0,1\}}\exp(y_ih_i)))\\
&=\frac{1}{Z}\exp(x^Ta)\exp(\sum_{i=1}^{N}\log(1+e^{y_i}+e^{-y_i}))\\
&=\frac{1}{Z}\exp(x^Ta)\exp(\sum_{i=1}^{N}\log(1+2cosh(y_i)))\\
&=\frac{1}{Z}\exp(x^Ta+\sum_{i=1}^{N}\log(1+2cosh(w_ix-b_i)))\\
\end{align*}
\begin{align*}
&=\frac{1}{Z}\exp(x^Ta+\sum_{i=1}^{N}\log(2(\frac{1}{2}+cosh(w_ix-b_i))))\\
&=\frac{1}{Z}\exp(x^Ta+\sum_{i=1}^{N}\log(2)+\log(\frac{1}{2}+cosh(w_ix-b_i)))\\
&=\frac{1}{Z}\exp(N\log(2)+x^Ta+\sum_{i=1}^{N}\log(\frac{1}{2}+cosh(w_ix-b_i)))\\
&=\frac{1}{Z}2^N\exp(x^Ta+\sum_{i=1}^{N}\log(\frac{1}{2}+cosh(w_ix-b_i)))\\
\end{align*}
With \[ Z':=\frac{2^N}{Z} \]
the desired result follows.\\
\textbf{(b)}\\
First compute gradients of $F$:
\begin{align*}
\bigtriangledown_{a_i}F(x)=\bigtriangledown_{a_i}-a^Tx=-x_i
\end{align*}
\begin{align*}
\bigtriangledown_{b_j}F(x)&=-\sum_{k=1}^{N}\bigtriangledown_{b_j}\log(\frac{1}{2}+cosh(w_kx-b_k))\\
&=-\bigtriangledown_{b_j}\log(\frac{1}{2}+cosh(w_jx-b_j))\\
&=-\frac{1}{\frac{1}{2}+cosh(w_kx-b_k)}\bigtriangledown_{b_j}cosh(w_jx-b_j)\\
&=-\frac{1}{\frac{1}{2}+cosh(w_kx-b_k)}sinh(w_jx-b_j)\bigtriangledown_{b_j}b_j\\
&=-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}
\end{align*}
\begin{align*}
\bigtriangledown_{w_{ij}}F(x)&=-\sum_{k=1}^{N}\bigtriangledown_{w_{ij}}\log(\frac{1}{2}+cosh(w_kx-b_k))\\
&=-\bigtriangledown_{w_{ij}}\log(\frac{1}{2}+cosh(w_jx-b_j))\\
&=-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}\bigtriangledown_{w_{ij}}(w_j^Tx)\\
&=-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}x_i
\end{align*}
Now we can plug the gradients into the expectations:\\
To compute the expectations with respect to the empirical distribution, we consider observed data points $x^{(1)},...,x^{(n)}$
\begin{align*}
\bigtriangledown_{a_i}KL(\hat{p}||p_{\theta})&=<-x_i>_{\hat{p}}-<-x_i>_{p_{\theta}}\\
&=\sum_{x\in\{0,1\}^d}x_ip_{\theta}(x)-<x_i>_{\hat{p}}\\
&=\sum_{x\in\{0,1\}^d}x_ip_{\theta}(x)-\frac{1}{n}\sum_{k=1}^{n}x^{(k)}_i\\
&=\frac{1}{Z'}\sum_{x\in\{0,1\}^d}x_i\exp(-F_{\theta}(x))-\frac{1}{n}\sum_{k=1}^{n}x^{(k)}_i\\
\end{align*}
\begin{align*}
\bigtriangledown_{b_j}KL(\hat{p}||p_{\theta})&=<-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}>_{\hat{p}}-<-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}>_{p_{\theta}}\\
&=\frac{1}{Z'}\sum_{x\in\{0,1\}^d}\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}\exp(-F_{\theta}(x))-\frac{1}{n}\sum_{k=1}^{n}\frac{sinh(w_jx^{(k)}-b_j)}{\frac{1}{2}+cosh(w_kx^{(k)}-b_k)}\\
\end{align*}
\begin{align*}
\bigtriangledown_{w_{ij}}KL(\hat{p}||p_{\theta})&=<-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}x_i>_{\hat{p}}-<-\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}x_i>_{p_{\theta}}\\
&=\frac{1}{Z'}\sum_{x\in\{0,1\}^d}\frac{sinh(w_jx-b_j)}{\frac{1}{2}+cosh(w_kx-b_k)}x_i\exp(-F_{\theta}(x))-\frac{1}{n}\sum_{k=1}^{n}\frac{sinh(w_jx^{(k)}-b_j)}{\frac{1}{2}+cosh(w_kx^{(k)}-b_k)}x^{(k)}_i\\
\end{align*}
\textbf{(c)} \\
The independence model is $(x_i \indep x_j \mid h)$ and $(h_i \indep h_j \mid x)$ for all $i\neq j$:   
\begin{gather*}
p(h \mid x) \stackrel{\text{Model}}{=} \prod_{j=1}^N {\Pr}_j(h_j \mid x)  
\end{gather*}

\begin{gather*}
p(h \mid x) = {p(h, x) \over p(x)} 
= 
\frac{\cancel{{1\over Z} e^{x^\top a}}\prod_j e^{h_jw_j^\top x + h_j b_j} }
{\cancel{{1\over Z} e^{x^\top a}}\prod_j (e^{w_j^\top x + b_j} + e^{-w_j^\top x - b_j} + 1)}
\stackrel{\text{Model}}{=}
\frac{\prod_j {\Pr}_j(h_j, x)}{\prod_j {\Pr}_j(x)}
=
\prod_j {\Pr}_j(h_j \mid x)
\end{gather*}
\begin{gather*}
\Longrightarrow
{\Pr}_j(h_j \mid x)
=
\frac{{\Pr}_j(h_j, x)}{{\Pr}_j(x)}
=
\frac{e^{h_jw^\top_jx + h_jb_j}} {\sum_{h_j} e^{h_jw^\top_jx + h_jb_j}}
=
\frac{e^{h_jw_j^\top x + h_j b_j} }
{e^{w_j^\top x + b_j} + e^{-w_j^\top x - b_j} + 1}
\end{gather*}
This is kind of a softmax function.
\begin{gather*}
{\Pr}_j(h_j = 1 \mid x)  
= 
\frac{e^{w_j^\top x + b_j} }
{e^{w_j^\top x + b_j} + e^{-w_j^\top x - b_j} + 1}
=
\frac{1}{1 + \exp(-2w_jx - 2b_j) + \exp(-w_jx - b_j)} 
\end{gather*}
\begin{gather*}
{\Pr}_j(h_j = -1 \mid x) 
= 
\frac{e^{-w_j^\top x - b_j} }
{e^{w_j^\top x + b_j} + e^{-w_j^\top x - b_j} + 1}
=
\frac{1}{\exp(2w_jx + 2b_j) + 1 + \exp(w_jx + b_j)} 
\end{gather*}
\begin{gather*}
{\Pr}_j(h_j = 0 \mid x)  
= 
\frac{1 }
{e^{w_j^\top x + b_j} + e^{-w_j^\top x - b_j} + 1}
=
\frac{1}{\exp(w_jx + b_j) +  \exp(-w_jx - b_j) + 1 }
\end{gather*}
\\
\\
\\
\begin{gather*}
p(x \mid h) \stackrel{\text{Model}}{=} \prod_{k=1}^d {\Pr}_k(x_k \mid h)  
\end{gather*}

\begin{gather*}
p(x \mid h) = {p(x, h) \over p(h)} 
= 
\frac{\cancel{{1\over Z} e^{h^\top b}}\prod_k e^{x_ka_k + x_kw_k^\top h} }
{\cancel{{1\over Z} e^{h^\top b}}\prod_k (1 + e^{a_k + w_k^\top h})}
\stackrel{\text{Model}}{=}
\frac{\prod_k {\Pr}_k(x_k, h)}{\prod_k {\Pr}_k(h)}
=
\prod_k {\Pr}_k(x_k \mid h)
\end{gather*}


\begin{gather*}
\Pr(x_k = 1 \mid h) 
=
\frac{e^{a_k + w_k^\top h} }
{1 + e^{a_k + w_k^\top h}}
=
\frac{1}
{e^{-a_k - w_k^\top h} + 1}
= 
\sigm(a_k + w_k^\top h)
\end{gather*}

\begin{gather*}
\Pr(x_k = 0 \mid h) 
=
\frac{1}
{1 + e^{a_k + w_k^\top h}}
=
\sigm(- a_k - w_k^\top h)
\end{gather*}
\end{document}






